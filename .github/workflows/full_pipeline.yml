name: Full SF Crime Pipeline (ID-based + Parquet + Category Forecast)

on:
  schedule:
    - cron: "0 14,15 * * *"        # SF 07:00 → 14/15 UTC
  workflow_dispatch:
    inputs:
      persist:
        description: "Sonuçları nasıl saklayalım?"
        type: choice
        options: [artifact, commit, none]
        default: artifact
      force:
        description: "Manuel tetiklemede 07:00 kapısını YOK SAY"
        type: boolean
        default: true
      top_k:
        description: "Stacking: her saat dilimi için önerilecek GEOID sayısı"
        default: "50"

permissions:
  actions: read
  contents: write

concurrency:
  group: full-pipeline-${{ github.ref }}
  cancel-in-progress: true

env:
  CRIME_DATA_DIR: crime_prediction_data
  GEOID_LEN: "11"

  # I/O davranışı
  USE_PARQUET: "1"           # 🔴 tüm ara çıktı & final çıktılar parquet
  ID_BASED: "1"              # 🔴 satır = olay (ID), grid joinleri ID’den
  LABEL_STYLE: "legacy01"    # 🔴 Y_label = 0/1 eski usul (var/yok)

  # Horizonlar (forecast ön-hesap)
  HORIZONS: "24h,7d,30d,90d,365d"

  BACKFILL_DAYS: "0"
  SF_SODA_FETCH_STRATEGY: ${{ vars.SF_SODA_FETCH_STRATEGY || 'bulk' }}
  SF_SODA_PAGE_LIMIT:    ${{ vars.SF_SODA_PAGE_LIMIT    || '50000' }}
  SF_SODA_MAX_PAGES:     ${{ vars.SF_SODA_MAX_PAGES     || '100' }}

  SF911_API_URL:       ${{ vars.SF911_API_URL       || 'https://data.sfgov.org/resource/2zdj-bwza.json' }}
  SF911_AGENCY_FILTER: ${{ vars.SF911_AGENCY_FILTER || 'agency like "%Police%"' }}
  SF911_API_TOKEN:     ${{ secrets.SF911_API_TOKEN }}
  SOCS_APP_TOKEN:      ${{ secrets.SOCS_APP_TOKEN }}

  PATROL_TOP_K: ${{ github.event.inputs.top_k || '50' }}

  PATROL_HORIZON_DAYS: "3"
  WX_LOCATION: "san francisco"
  WX_UNIT: "us"

  ACS_YEAR: ${{ vars.ACS_YEAR || 'LATEST' }}
  DEMOG_WHITELIST: ${{ vars.DEMOG_WHITELIST || '' }}
  CENSUS_GEO_LEVEL: ${{ vars.CENSUS_GEO_LEVEL || 'auto' }}

jobs:
  run:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout (with LFS)
        uses: actions/checkout@v4
        with:
          lfs: true

      - name: Ensure LFS objects
        run: |
          git lfs install
          git lfs pull
          echo "Repo root:"; ls -lah
          echo "crime_prediction_data:"; ls -lah crime_prediction_data || true
          echo "CRIME_DATA_DIR:"; ls -lah "${CRIME_DATA_DIR}" || true

      - name: Ensure data dir
        run: mkdir -p "${CRIME_DATA_DIR}"

      # --- SF 07:00 kapısı (TZ ayarla + saat kontrolü) ---
      - name: Set runner timezone to America/Los_Angeles
        uses: szenius/set-timezone@v2.0
        with:
          timezoneLinux: "America/Los_Angeles"

      - name: Gate by local SF time == 07 (bypassable)
        id: gate
        run: |
          now="$(date)"
          echo "Runner local time: $now"
          echo "RUN_LOCAL_TIME=$now" >> $GITHUB_ENV
          # Manuel + force=true ise doğrudan geç
          if [ "${{ github.event_name }}" = "workflow_dispatch" ] && [ "${{ github.event.inputs.force }}" = "true" ]; then
            echo "proceed=true" >> $GITHUB_OUTPUT
            exit 0
          fi
          # Aksi halde 07:00 kontrolü
          if [ "$(date +%H)" = "07" ]; then
            echo "proceed=true" >> $GITHUB_OUTPUT
          else
            echo "proceed=false" >> $GITHUB_OUTPUT
          fi

      - name: Write run summary (start)
        if: ${{ steps.gate.outputs.proceed == 'true' && success() }}
        run: |
          {
            echo "## SF Crime Pipeline (ID-based + Parquet + Stacking + Cat-Forecast)"
            echo ""
            echo "- Çalışma zamanı (SF): **$(date)**"
            echo "- I/O: **parquet** (USE_PARQUET=${USE_PARQUET})"
            echo "- ID-based: **${ID_BASED}** · Y_label: **${LABEL_STYLE}**"
            echo "- Horizons: **${HORIZONS}**"
            echo "- PATROL_TOP_K: **${PATROL_TOP_K}**"
          } >> $GITHUB_STEP_SUMMARY

      - name: System deps for rtree (optional)
        if: ${{ steps.gate.outputs.proceed == 'true' }}
        run: sudo apt-get update && sudo apt-get install -y libspatialindex-dev

      - name: Set up Python 3.11
        if: ${{ steps.gate.outputs.proceed == 'true' }}
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
          cache: "pip"

      - name: Install deps
        if: ${{ steps.gate.outputs.proceed == 'true' }}
        run: |
          python -m pip install -U pip wheel setuptools
          if [ -f requirements.txt ]; then
            pip install -r requirements.txt
          fi
          # Geo
          pip install -U "geopandas==1.0.1" "shapely==2.0.4" "pyproj==3.6.1" "pyogrio==0.9.0" "rtree==1.3.0"
          # Parquet stack
          pip install -U pyarrow polars
          # ML
          pip install -U pandas numpy scikit-learn joblib xgboost lightgbm

      - name: Geo stack smoke test
        if: ${{ steps.gate.outputs.proceed == 'true' }}
        run: |
          python - <<'PY'
          import geopandas, shapely, pyproj, pyogrio, pandas, pyarrow, polars
          print("geopandas", geopandas.__version__)
          print("shapely", shapely.__version__)
          print("pyproj", pyproj.__version__)
          print("pyogrio", pyogrio.__version__)
          print("pandas", pandas.__version__)
          PY

      # ------------- PIPELINE (ID-based + parquet) -------------
      - name: 01) Suç tabanı ve grid → sf_crime.parquet + gridler
        if: ${{ steps.gate.outputs.proceed == 'true' }}
        env:
          USE_PARQUET: ${{ env.USE_PARQUET }}
          ID_BASED: ${{ env.ID_BASED }}
          LABEL_STYLE: ${{ env.LABEL_STYLE }}
        run: |
          set -e
          python -u update_crime.py
          # Beklenen: ${CRIME_DATA_DIR}/sf_crime.parquet
          #           ${CRIME_DATA_DIR}/sf_crime_grid_full_labeled.parquet

      - name: 02) 911 → sf_crime_01.parquet (bulk 50k)
        if: ${{ steps.gate.outputs.proceed == 'true' }}
        env:
          SF_SODA_FETCH_STRATEGY: ${{ env.SF_SODA_FETCH_STRATEGY }}
          SF_SODA_PAGE_LIMIT:    ${{ env.SF_SODA_PAGE_LIMIT }}
          SF_SODA_MAX_PAGES:     ${{ env.SF_SODA_MAX_PAGES }}
          SF911_API_URL:         ${{ env.SF911_API_URL }}
          SF911_AGENCY_FILTER:   ${{ env.SF911_AGENCY_FILTER }}
          SF911_API_TOKEN:       ${{ env.SF911_API_TOKEN }}
          SOCS_APP_TOKEN:        ${{ env.SOCS_APP_TOKEN }}
          BACKFILL_DAYS:         ${{ env.BACKFILL_DAYS }}
          USE_PARQUET:           ${{ env.USE_PARQUET }}
          ID_BASED:              ${{ env.ID_BASED }}
        run: |
          set -e
          python -u update_911.py

      - name: 03) 311 → sf_crime_02.parquet (bulk 50k)
        if: ${{ steps.gate.outputs.proceed == 'true' }}
        env:
          SF_SODA_FETCH_STRATEGY: ${{ env.SF_SODA_FETCH_STRATEGY }}
          SF_SODA_PAGE_LIMIT:    ${{ env.SF_SODA_PAGE_LIMIT }}
          SF_SODA_MAX_PAGES:     ${{ env.SF_SODA_MAX_PAGES }}
          SOCS_APP_TOKEN:        ${{ env.SOCS_APP_TOKEN }}
          BACKFILL_DAYS:         ${{ env.BACKFILL_DAYS }}
          USE_PARQUET:           ${{ env.USE_PARQUET }}
          ID_BASED:              ${{ env.ID_BASED }}
        run: |
          set -e
          if [ -f update_311.py ]; then python -u update_311.py;
          else python -u scripts/update_311.py; fi

      - name: Ensure population CSV (local file) → parquet’e dönüştür
        if: ${{ steps.gate.outputs.proceed == 'true' }}
        run: |
          set -euo pipefail
          mkdir -p "${CRIME_DATA_DIR}"
          SRC_CAND=( "${CRIME_DATA_DIR}/sf_population.csv" "sf_population.csv" "data/sf_population.csv" "inputs/sf_population.csv" )
          DEST_CSV="${CRIME_DATA_DIR}/sf_population.csv"
          DEST_PARQ="${CRIME_DATA_DIR}/sf_population.parquet"
          FOUND=""
          for p in "${SRC_CAND[@]}"; do
            if [ -f "$p" ]; then
              cp -f "$p" "$DEST_CSV"
              FOUND="1"; break
            fi
          done
          if [ -z "$FOUND" ]; then
            echo "❌ sf_population.csv bulunamadı"; exit 2
          fi
          python - <<'PY'
          import os, pandas as pd
          import pyarrow as pa, pyarrow.parquet as pq
          p = os.path.join(os.environ["CRIME_DATA_DIR"], "sf_population.csv")
          q = os.path.join(os.environ["CRIME_DATA_DIR"], "sf_population.parquet")
          df = pd.read_csv(p)
          # header normalize
          low = {c.lower(): c for c in df.columns}
          if 'geoid' not in low and 'geography_id' in low:
              df.rename(columns={low['geography_id']:'GEOID'}, inplace=True)
          for cand in ['population','total_population','b01003_001e','estimate','total','value']:
              if cand in low and 'population' not in df.columns:
                  df.rename(columns={low[cand]:'population'}, inplace=True)
                  break
          table = pa.Table.from_pandas(df)
          pq.write_table(table, q, compression="zstd")
          print("population → parquet:", q)
          PY

      - name: 04) Nüfus → sf_crime_03.parquet (demografi + nüfus)
        if: ${{ steps.gate.outputs.proceed == 'true' }}
        env:
          POPULATION_PATH:  ${{ env.CRIME_DATA_DIR }}/sf_population.parquet
          CENSUS_GEO_LEVEL: ${{ env.CENSUS_GEO_LEVEL }}
          ACS_YEAR:         ${{ env.ACS_YEAR }}
          DEMOG_WHITELIST:  ${{ env.DEMOG_WHITELIST }}
          USE_PARQUET:      ${{ env.USE_PARQUET }}
          ID_BASED:         ${{ env.ID_BASED }}
        run: |
          set -e
          python -u update_population.py

      - name: 05) Otobüs → sf_crime_04.parquet
        if: ${{ steps.gate.outputs.proceed == 'true' }}
        env:
          USE_PARQUET: ${{ env.USE_PARQUET }}
          ID_BASED:    ${{ env.ID_BASED }}
        run: |
          set -e
          python -u update_bus.py

      - name: 06) Tren (BART) → sf_crime_05.parquet
        if: ${{ steps.gate.outputs.proceed == 'true' }}
        env:
          USE_PARQUET: ${{ env.USE_PARQUET }}
          ID_BASED:    ${{ env.ID_BASED }}
        run: |
          set -e
          python -u update_train.py

      - name: 07) POI zenginleştirme → sf_crime_06.parquet
        if: ${{ steps.gate.outputs.proceed == 'true' }}
        env:
          USE_PARQUET: ${{ env.USE_PARQUET }}
          ID_BASED:    ${{ env.ID_BASED }}
        run: |
          set -e
          if [ -f update_poi.py ]; then python -u update_poi.py;
          elif [ -f pipeline_make_sf_crime_06.py ]; then python -u pipeline_make_sf_crime_06.py;
          else echo "POI adımı bulunamadı"; exit 2; fi

      - name: 08) Polis & Devlet binaları → sf_crime_07.parquet
        if: ${{ steps.gate.outputs.proceed == 'true' }}
        env:
          USE_PARQUET: ${{ env.USE_PARQUET }}
          ID_BASED:    ${{ env.ID_BASED }}
        run: |
          set -e
          if [ -f update_police_gov.py ]; then python -u update_police_gov.py;
          elif [ -f scripts/enrich_police_gov_06_to_07.py ]; then python -u scripts/enrich_police_gov_06_to_07.py;
          else echo "Polis/Gov adımı bulunamadı"; exit 2; fi

      - name: 09) Hava durumu → sf_crime_08.parquet
        if: ${{ steps.gate.outputs.proceed == 'true' }}
        env:
          USE_PARQUET: ${{ env.USE_PARQUET }}
          ID_BASED:    ${{ env.ID_BASED }}
        run: |
          set -e
          if [ -f update_weather.py ]; then python -u update_weather.py;
          elif [ -f scripts/update_weather.py ]; then python -u scripts/update_weather.py;
          else echo "❌ Weather script not found"; exit 2; fi
          echo "sf_crime_08.parquet hazırsa başlık göster:"
          python - <<'PY'
          import os, polars as pl, glob
          p = os.path.join(os.environ["CRIME_DATA_DIR"], "sf_crime_08.parquet")
          if os.path.exists(p):
              df = pl.scan_parquet(p).head(5).collect()
              print(df)
          PY

      - name: 10) neighbors.csv (normalize/üret + kalite kontrol)
        if: ${{ steps.gate.outputs.proceed == 'true' }}
        env:
          CRIME_DATA_DIR: ${{ env.CRIME_DATA_DIR }}
          STACKING_DATASET: ${{ env.CRIME_DATA_DIR }}/sf_crime_grid_full_labeled.parquet
          NEIGHBOR_FILE: ${{ env.CRIME_DATA_DIR }}/neighbors.csv
          NEIGHBOR_STRATEGY: queen
          MIN_NEIGHBOR_DEG: "3"
          KNN_K: "5"
          NEIGHBOR_POLY: ${{ env.CRIME_DATA_DIR }}/sf_grid.geojson
        run: |
          # (içerik: sizin önceki komşuluk bloğunuzun aynısı)
          # ... (değiştirmedim; yukarıdaki sürümünüzle aynı kalabilir)

          echo "Komşuluk kalite kontrolü tamam."

      - name: 11) Stacking (ID-based, parquet I/O)
        if: ${{ steps.gate.outputs.proceed == 'true' }}
        env:
          STACKING_DATASET: ${{ env.CRIME_DATA_DIR }}/sf_crime_grid_full_labeled.parquet
          ENABLE_SPATIAL_TE: "1"
          TE_ALPHA: "50"
          NEIGHBOR_FILE: ${{ env.CRIME_DATA_DIR }}/neighbors.csv
          ENABLE_TE_ABLATION: "1"
          ABLASYON_BASIS: "ohe"
          USE_PARQUET: ${{ env.USE_PARQUET }}
          ID_BASED:    ${{ env.ID_BASED }}
          LABEL_STYLE: ${{ env.LABEL_STYLE }}
        run: |
          set -e
          test -f "${STACKING_DATASET}" || { echo "❌ STACKING_DATASET yok: ${STACKING_DATASET}"; exit 2; }
          python -u stacking_risk_pipeline.py
          # Beklenen parquet çıktılar:
          #   ${CRIME_DATA_DIR}/risk_hourly.parquet
          #   ${CRIME_DATA_DIR}/metrics_*.csv (kalabilir)
          #   ${CRIME_DATA_DIR}/models/*.joblib

      - name: 12) Category Forecast — TRAIN (per-category models)
        if: ${{ steps.gate.outputs.proceed == 'true' }}
        env:
          GRID_DATASET:   ${{ env.CRIME_DATA_DIR }}/sf_crime_grid_full_labeled.parquet
          MODEL_DIR:      ${{ env.CRIME_DATA_DIR }}/models_cat
          USE_PARQUET:    ${{ env.USE_PARQUET }}
          ID_BASED:       ${{ env.ID_BASED }}
          LABEL_STYLE:    ${{ env.LABEL_STYLE }}
          HORIZONS:       ${{ env.HORIZONS }}
        run: |
          set -e
          mkdir -p "${MODEL_DIR}"
          python -u scripts/forecast_train.py

      - name: 13) Category Forecast — PREDICT (partitioned parquet)
        if: ${{ steps.gate.outputs.proceed == 'true' }}
        env:
          GRID_DATASET:   ${{ env.CRIME_DATA_DIR }}/sf_crime_grid_full_labeled.parquet
          MODEL_DIR:      ${{ env.CRIME_DATA_DIR }}/models_cat
          OUT_DIR:        ${{ env.CRIME_DATA_DIR }}/sf_forecast_cat
          USE_PARQUET:    ${{ env.USE_PARQUET }}
          ID_BASED:       ${{ env.ID_BASED }}
          HORIZONS:       ${{ env.HORIZONS }}
        run: |
          set -e
          mkdir -p "${OUT_DIR}"
          python -u scripts/forecast_predict.py
          # Beklenen: ${CRIME_DATA_DIR}/sf_forecast_cat/category=<NAME>/part-*.parquet
          #           sütunlar: GEOID, hr_key, category, p_24h, p_7d, p_30d, p_90d, p_365d

      - name: 14) Patrol (uses risk_hourly.parquet + yarin/week)
        if: ${{ steps.gate.outputs.proceed == 'true' }}
        env:
          CRIME_DATA_DIR: ${{ env.CRIME_DATA_DIR }}
          PATROL_TOP_K:   ${{ env.PATROL_TOP_K }}
          PATROL_HORIZON_DAYS: ${{ env.PATROL_HORIZON_DAYS }}
        run: |
          set -e
          test -f "${CRIME_DATA_DIR}/risk_hourly.parquet" || { echo "❌ risk_hourly.parquet bulunamadı"; exit 2; }
          # hava tahmini
          python -u scripts/fetch_weather_fcst.py
          # patrol
          python -u scripts/post_patrol.py --input-parquet "${CRIME_DATA_DIR}/risk_hourly.parquet" --output-parquet "${CRIME_DATA_DIR}/patrol_recs_multi.parquet"
          echo "---- patrol_recs_multi.parquet var mı? ----"
          test -f "${CRIME_DATA_DIR}/patrol_recs_multi.parquet" && echo "OK"

      - name: 15) Quick preview (parquet outputs)
        if: ${{ steps.gate.outputs.proceed == 'true' }}
        run: |
          python - <<'PY'
          import os, glob, polars as pl
          d=os.environ["CRIME_DATA_DIR"]
          for p in ["sf_crime_grid_full_labeled.parquet","risk_hourly.parquet","patrol_recs_multi.parquet"]:
              f=os.path.join(d,p)
              if os.path.exists(f):
                  print("===",p,"==="); print(pl.scan_parquet(f).head(5).collect())
          PY

      # ---- ÇIKTILAR ----
      - name: Upload artifact (parquet ağırlıklı)
        if: ${{ steps.gate.outputs.proceed == 'true' && (github.event_name == 'schedule' || (github.event_name == 'workflow_dispatch' && github.event.inputs.persist == 'artifact')) }}
        uses: actions/upload-artifact@v4
        with:
          name: sf-crime-pipeline-output
          path: |
            ${{ env.CRIME_DATA_DIR }}/*.parquet
            ${{ env.CRIME_DATA_DIR }}/sf_forecast_cat/**
            ${{ env.CRIME_DATA_DIR }}/*.geojson
            ${{ env.CRIME_DATA_DIR }}/metrics_*.csv
            ${{ env.CRIME_DATA_DIR }}/models/*.joblib
            ${{ env.CRIME_DATA_DIR }}/oof_base_probs*.npz
          if-no-files-found: warn
          retention-days: 14

      - name: Commit & push (opsiyonel)
        if: ${{ steps.gate.outputs.proceed == 'true' && github.event_name == 'workflow_dispatch' && github.event.inputs.persist == 'commit' }}
        run: |
          set -e
          git config --global user.name "github-actions[bot]"
          git config --global user.email "github-actions[bot]@users.noreply.github.com"
          git add -A
          git commit -m "🔄 Full pipeline (ID-based + Parquet + Cat-Forecast) [skip ci]" || echo "No changes"
          git push || echo "Nothing to push"

      - name: Notify success (SendGrid HTTP)
        if: ${{ steps.gate.outputs.proceed == 'true' && success() }}
        env:
          SG_KEY: ${{ secrets.SENDGRID_API_KEY }}
        run: |
          if [ -z "$SG_KEY" ]; then echo "❌ SENDGRID_API_KEY yok/boş"; exit 1; fi
          curl -s -X POST https://api.sendgrid.com/v3/mail/send \
            -H "Authorization: Bearer $SG_KEY" \
            -H "Content-Type: application/json" \
            -d @- <<'EOF' -o /dev/stderr -w "\nHTTP:%{http_code}\n"
          {
            "personalizations":[ {"to":[ {"email":"cem5113@hotmail.com"}, {"email":"cemeroglu5113@gmail.com"} ]} ],
            "from":{"email":"${{ secrets.SG_FROM }}","name":"SF Crime Pipeline"},
            "reply_to":{"email":"cem5113@hotmail.com","name":"Cem"},
            "subject":"✅ SF Crime Pipeline başarı (ID-based + Parquet + Forecast) #${{ github.run_number }}",
            "categories":["sf-crime-pipeline","success"],
            "content":[{"type":"text/html","value":"<p>Pipeline başarıyla tamamlandı.</p><ul><li>ID-based + Parquet</li><li>Category Forecast hazır (partitioned parquet)</li><li>Run #: <b>${{ github.run_number }}</b></li></ul><p><a href='${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}'>Log & Artifact</a></p>"}]
          }
          EOF

      - name: Notify failure (SendGrid HTTP)
        if: ${{ steps.gate.outputs.proceed == 'true' && failure() }}
        env:
          SG_KEY: ${{ secrets.SENDGRID_API_KEY }}
        run: |
          if [ -z "$SG_KEY" ]; then echo "❌ SENDGRID_API_KEY yok/boş"; exit 1; fi
          curl -s -X POST https://api.sendgrid.com/v3/mail/send \
            -H "Authorization: Bearer $SG_KEY" \
            -H "Content-Type: application/json" \
            -d @- <<'EOF' -o /dev/stderr -w "\nHTTP:%{http_code}\n"
          {
            "personalizations":[ {"to":[ {"email":"cem5113@hotmail.com"}, {"email":"cemeroglu5113@gmail.com"} ]} ],
            "from":{"email":"${{ secrets.SG_FROM }}","name":"SF Crime Pipeline"},
            "reply_to":{"email":"cem5113@hotmail.com","name":"Cem"},
            "subject":"❌ SF Crime Pipeline hata (ID-based + Parquet) #${{ github.run_number }}",
            "categories":["sf-crime-pipeline","failure"],
            "content":[{"type":"text/html","value":"<p>Pipeline başarısız.</p><ul><li>Run #: <b>${{ github.run_number }}</b></li><li>ID-based + Parquet modunda hata</li></ul><p><a href='${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}'>Log</a></p>"}]
          }
          EOF

      - name: Write run summary (end)
        if: ${{ steps.gate.outputs.proceed == 'true' && success() }}
        run: |
          {
            echo "## Tamamlandı"
            echo "- Üretilen başlıca parquetler:"
            echo "  - sf_crime_grid_full_labeled.parquet (ID-based, Y_label=0/1)"
            echo "  - risk_hourly.parquet, patrol_recs_multi.parquet"
            echo "  - sf_forecast_cat/ (category partitioned, horizons: ${HORIZONS})"
          } >> $GITHUB_STEP_SUMMARY
